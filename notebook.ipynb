{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Devops Drug Classification - TensorFlow Lite Model\n",
    "\n",
    "This notebook demonstrates the training, evaluation, and conversion to TensorFlow Lite (TFLite) for the Drug Classification model, replacing the previous scikit-learn pipeline. It includes saving the necessary preprocessing objects and the TFLite model for use in the accompanying application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 00:11:15.817908: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 00:11:15.819686: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-23 00:11:15.828825: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-23 00:11:15.840111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745347275.855840   34627 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745347275.860156   34627 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745347275.875217   34627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745347275.875235   34627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745347275.875236   34627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745347275.875237   34627 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-23 00:11:15.879984: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skops.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>16.753</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>74</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>11.939</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12.854</td>\n",
       "      <td>drugA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>16.850</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>6.769</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "123   36   F  NORMAL        HIGH   16.753  DrugY\n",
       "135   74   M     LOW      NORMAL   11.939  drugX\n",
       "101   45   F    HIGH        HIGH   12.854  drugA\n",
       "109   23   M  NORMAL        HIGH   16.850  DrugY\n",
       "193   72   M     LOW        HIGH    6.769  drugC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug_df = pd.read_csv(\"Data/drug.csv\")\n",
    "drug_df = drug_df.sample(frac=1, random_state=125) # Added random_state for reproducibility\n",
    "\n",
    "print(\"Dataset head:\")\n",
    "display(drug_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Setup and Application\n",
    "\n",
    "We define the preprocessing steps using scikit-learn transformers. These will be fitted on the full dataset and then applied. The fitted preprocessors will be saved for later use in the inference application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting preprocessors...\n",
      "Preprocessing complete.\n",
      "Original features shape: (200, 5)\n",
      "Processed features shape: (200, 5)\n",
      "Original labels shape: (200,)\n",
      "Encoded labels shape: (200,)\n",
      "Label mapping: {'DrugY': 0, 'drugA': 1, 'drugB': 2, 'drugC': 3, 'drugX': 4}\n"
     ]
    }
   ],
   "source": [
    "# Split out raw arrays\n",
    "# Assuming the column order is fixed: Age, Sex, BP, Cholesterol, Na_to_K, Drug\n",
    "# Indices: 0:Age (num), 1:Sex (cat), 2:BP (cat), 3:Cholesterol (cat), 4:Na_to_K (num), 5:Drug (target)\n",
    "cat_cols_idx = [1, 2, 3] # Sex, BP, Cholesterol\n",
    "num_cols_idx = [0, 4] # Age, Na_to_K\n",
    "\n",
    "X_raw = drug_df.drop(\"Drug\", axis=1).values\n",
    "y_raw = drug_df.Drug.values\n",
    "\n",
    "# Define and fit preprocessing steps separately using the full raw data\n",
    "# 1️⃣ Impute & encode categoricals\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# 2️⃣ Impute & scale numerics\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply imputers and encoders/scalers sequentially to handle dependencies\n",
    "# These fitted preprocessors will be saved for the app\n",
    "print(\"Fitting preprocessors...\")\n",
    "# Apply categorical imputer first\n",
    "X_cat_imputed = cat_imputer.fit_transform(X_raw[:, cat_cols_idx])\n",
    "# Apply ordinal encoder\n",
    "X_cat_processed = encoder.fit_transform(X_cat_imputed)\n",
    "\n",
    "# Apply numerical imputer\n",
    "X_num_imputed = num_imputer.fit_transform(X_raw[:, num_cols_idx])\n",
    "# Apply standard scaler\n",
    "X_num_processed = scaler.fit_transform(X_num_imputed)\n",
    "\n",
    "# 3️⃣ Stack into one feature matrix\n",
    "X_processed = np.hstack([X_cat_processed, X_num_processed])\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: i for i,label in enumerate(np.unique(y_raw))}\n",
    "y_encoded = np.vectorize(label_mapping.get)(y_raw)\n",
    "\n",
    "print(f\"Original features shape: {X_raw.shape}\")\n",
    "print(f\"Processed features shape: {X_processed.shape}\")\n",
    "print(f\"Original labels shape: {y_raw.shape}\")\n",
    "print(f\"Encoded labels shape: {y_encoded.shape}\")\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (140, 5)\n",
      "X_test shape: (60, 5)\n",
      "y_train shape: (140,)\n",
      "y_test shape: (60,)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split using the processed features and encoded labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded, test_size=0.3, random_state=125, stratify=y_encoded # Use stratify with encoded labels\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Preprocessors and Label Mapping\n",
    "\n",
    "Save the fitted scikit-learn preprocessors and the label mapping using `skops`. These files will be used by the application to preprocess new data points before feeding them to the TFLite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessors and label mapping...\n",
      "Preprocessors and label mapping saved in Model/.\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted preprocessors and the label mapping using skops\n",
    "print(\"Saving preprocessors and label mapping...\")\n",
    "sio.dump(cat_imputer, \"Model/cat_imputer.skops\")\n",
    "sio.dump(encoder, \"Model/encoder.skops\")\n",
    "sio.dump(num_imputer, \"Model/num_imputer.skops\")\n",
    "sio.dump(scaler, \"Model/scaler.skops\")\n",
    "sio.dump(label_mapping, \"Model/label_mapping.skops\")\n",
    "print(\"Preprocessors and label mapping saved in Model/.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorFlow Model Definition and Training\n",
    "\n",
    "Define and train the simple Keras Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745347298.071623   34627 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1745347298.090995   34627 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m45\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">277</span> (1.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m277\u001b[0m (1.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">277</span> (1.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m277\u001b[0m (1.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A very small MLP\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(label_mapping), activation='softmax') # Output layer matches the number of drug classes\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TensorFlow model...\n",
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1220 - loss: 1.7074 - val_accuracy: 0.3571 - val_loss: 1.5944\n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1471 - loss: 1.6636 - val_accuracy: 0.2857 - val_loss: 1.5423\n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2664 - loss: 1.5992 - val_accuracy: 0.3571 - val_loss: 1.4953\n",
      "Epoch 4/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2840 - loss: 1.5388 - val_accuracy: 0.4286 - val_loss: 1.4505\n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3828 - loss: 1.4886 - val_accuracy: 0.3571 - val_loss: 1.4083\n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4141 - loss: 1.4706 - val_accuracy: 0.3571 - val_loss: 1.3716\n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4625 - loss: 1.4193 - val_accuracy: 0.4286 - val_loss: 1.3374\n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4403 - loss: 1.3925 - val_accuracy: 0.5000 - val_loss: 1.3074\n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4652 - loss: 1.3214 - val_accuracy: 0.5000 - val_loss: 1.2788\n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4595 - loss: 1.3394 - val_accuracy: 0.5000 - val_loss: 1.2529\n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4512 - loss: 1.3434 - val_accuracy: 0.5000 - val_loss: 1.2288\n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5036 - loss: 1.1910 - val_accuracy: 0.5000 - val_loss: 1.2038\n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4522 - loss: 1.2169 - val_accuracy: 0.5000 - val_loss: 1.1803\n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4919 - loss: 1.1784 - val_accuracy: 0.5000 - val_loss: 1.1587\n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4201 - loss: 1.1938 - val_accuracy: 0.5000 - val_loss: 1.1332\n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5313 - loss: 1.0640 - val_accuracy: 0.5000 - val_loss: 1.1088\n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5248 - loss: 1.0849 - val_accuracy: 0.5000 - val_loss: 1.0826\n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5551 - loss: 1.0690 - val_accuracy: 0.5000 - val_loss: 1.0566\n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6383 - loss: 1.0060 - val_accuracy: 0.5000 - val_loss: 1.0333\n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6241 - loss: 0.9845 - val_accuracy: 0.4286 - val_loss: 1.0090\n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6463 - loss: 0.9312 - val_accuracy: 0.4286 - val_loss: 0.9876\n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6538 - loss: 0.9162 - val_accuracy: 0.5000 - val_loss: 0.9663\n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6002 - loss: 0.9685 - val_accuracy: 0.5000 - val_loss: 0.9487\n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6843 - loss: 0.8833 - val_accuracy: 0.5714 - val_loss: 0.9304\n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6301 - loss: 0.8956 - val_accuracy: 0.6429 - val_loss: 0.9141\n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6896 - loss: 0.8095 - val_accuracy: 0.6429 - val_loss: 0.8998\n",
      "Epoch 27/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7108 - loss: 0.7866 - val_accuracy: 0.6429 - val_loss: 0.8866\n",
      "Epoch 28/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6885 - loss: 0.8132 - val_accuracy: 0.6429 - val_loss: 0.8743\n",
      "Epoch 29/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7178 - loss: 0.7492 - val_accuracy: 0.6429 - val_loss: 0.8638\n",
      "Epoch 30/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7031 - loss: 0.7527 - val_accuracy: 0.6429 - val_loss: 0.8540\n",
      "Epoch 31/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7180 - loss: 0.8001 - val_accuracy: 0.6429 - val_loss: 0.8451\n",
      "Epoch 32/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7134 - loss: 0.7209 - val_accuracy: 0.6429 - val_loss: 0.8356\n",
      "Epoch 33/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7226 - loss: 0.6896 - val_accuracy: 0.6429 - val_loss: 0.8254\n",
      "Epoch 34/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7150 - loss: 0.6791 - val_accuracy: 0.6429 - val_loss: 0.8169\n",
      "Epoch 35/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6801 - loss: 0.7669 - val_accuracy: 0.6429 - val_loss: 0.8115\n",
      "Epoch 36/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7308 - loss: 0.6537 - val_accuracy: 0.6429 - val_loss: 0.8017\n",
      "Epoch 37/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7062 - loss: 0.6693 - val_accuracy: 0.6429 - val_loss: 0.7943\n",
      "Epoch 38/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.6573 - val_accuracy: 0.6429 - val_loss: 0.7883\n",
      "Epoch 39/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.6110 - val_accuracy: 0.6429 - val_loss: 0.7820\n",
      "Epoch 40/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7966 - loss: 0.5820 - val_accuracy: 0.6429 - val_loss: 0.7772\n",
      "Epoch 41/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7898 - loss: 0.5990 - val_accuracy: 0.6429 - val_loss: 0.7691\n",
      "Epoch 42/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7860 - loss: 0.6242 - val_accuracy: 0.7143 - val_loss: 0.7629\n",
      "Epoch 43/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.6051 - val_accuracy: 0.7143 - val_loss: 0.7554\n",
      "Epoch 44/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7935 - loss: 0.5258 - val_accuracy: 0.7143 - val_loss: 0.7486\n",
      "Epoch 45/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7594 - loss: 0.5426 - val_accuracy: 0.7143 - val_loss: 0.7440\n",
      "Epoch 46/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7982 - loss: 0.5597 - val_accuracy: 0.7143 - val_loss: 0.7378\n",
      "Epoch 47/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7948 - loss: 0.4967 - val_accuracy: 0.7143 - val_loss: 0.7292\n",
      "Epoch 48/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8104 - loss: 0.5134 - val_accuracy: 0.7143 - val_loss: 0.7235\n",
      "Epoch 49/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7981 - loss: 0.5380 - val_accuracy: 0.7143 - val_loss: 0.7188\n",
      "Epoch 50/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7946 - loss: 0.5587 - val_accuracy: 0.7143 - val_loss: 0.7139\n",
      "Epoch 51/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8327 - loss: 0.4932 - val_accuracy: 0.7143 - val_loss: 0.7075\n",
      "Epoch 52/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8472 - loss: 0.5342 - val_accuracy: 0.7143 - val_loss: 0.6999\n",
      "Epoch 53/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.4522 - val_accuracy: 0.7143 - val_loss: 0.6962\n",
      "Epoch 54/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.5143 - val_accuracy: 0.7143 - val_loss: 0.6901\n",
      "Epoch 55/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8468 - loss: 0.5135 - val_accuracy: 0.7143 - val_loss: 0.6851\n",
      "Epoch 56/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9009 - loss: 0.4464 - val_accuracy: 0.7143 - val_loss: 0.6752\n",
      "Epoch 57/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.4625 - val_accuracy: 0.7143 - val_loss: 0.6717\n",
      "Epoch 58/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8555 - loss: 0.4895 - val_accuracy: 0.7143 - val_loss: 0.6652\n",
      "Epoch 59/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.4370 - val_accuracy: 0.7143 - val_loss: 0.6612\n",
      "Epoch 60/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.4377 - val_accuracy: 0.7143 - val_loss: 0.6602\n",
      "Epoch 61/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9211 - loss: 0.3530 - val_accuracy: 0.7143 - val_loss: 0.6528\n",
      "Epoch 62/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8969 - loss: 0.3795 - val_accuracy: 0.7143 - val_loss: 0.6443\n",
      "Epoch 63/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9151 - loss: 0.3669 - val_accuracy: 0.7143 - val_loss: 0.6371\n",
      "Epoch 64/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8597 - loss: 0.4241 - val_accuracy: 0.7143 - val_loss: 0.6377\n",
      "Epoch 65/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9244 - loss: 0.3899 - val_accuracy: 0.7143 - val_loss: 0.6296\n",
      "Epoch 66/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8850 - loss: 0.4099 - val_accuracy: 0.7143 - val_loss: 0.6229\n",
      "Epoch 67/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.3931 - val_accuracy: 0.7143 - val_loss: 0.6226\n",
      "Epoch 68/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9185 - loss: 0.3713 - val_accuracy: 0.7143 - val_loss: 0.6208\n",
      "Epoch 69/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.3581 - val_accuracy: 0.7143 - val_loss: 0.6159\n",
      "Epoch 70/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9120 - loss: 0.3982 - val_accuracy: 0.7143 - val_loss: 0.6085\n",
      "Epoch 71/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.3458 - val_accuracy: 0.7143 - val_loss: 0.6052\n",
      "Epoch 72/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9104 - loss: 0.3621 - val_accuracy: 0.7143 - val_loss: 0.5989\n",
      "Epoch 73/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.3296 - val_accuracy: 0.7143 - val_loss: 0.5945\n",
      "Epoch 74/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9307 - loss: 0.3583 - val_accuracy: 0.7143 - val_loss: 0.5900\n",
      "Epoch 75/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9001 - loss: 0.3594 - val_accuracy: 0.7857 - val_loss: 0.5817\n",
      "Epoch 76/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9088 - loss: 0.3758 - val_accuracy: 0.7857 - val_loss: 0.5755\n",
      "Epoch 77/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9100 - loss: 0.3839 - val_accuracy: 0.7857 - val_loss: 0.5709\n",
      "Epoch 78/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9195 - loss: 0.3329 - val_accuracy: 0.7143 - val_loss: 0.5688\n",
      "Epoch 79/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9015 - loss: 0.3045 - val_accuracy: 0.7143 - val_loss: 0.5632\n",
      "Epoch 80/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8997 - loss: 0.3216 - val_accuracy: 0.7857 - val_loss: 0.5601\n",
      "Epoch 81/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9123 - loss: 0.3235 - val_accuracy: 0.7857 - val_loss: 0.5528\n",
      "Epoch 82/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9201 - loss: 0.2958 - val_accuracy: 0.7857 - val_loss: 0.5443\n",
      "Epoch 83/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8862 - loss: 0.3208 - val_accuracy: 0.7857 - val_loss: 0.5453\n",
      "Epoch 84/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.3545 - val_accuracy: 0.7857 - val_loss: 0.5375\n",
      "Epoch 85/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9478 - loss: 0.2553 - val_accuracy: 0.7857 - val_loss: 0.5344\n",
      "Epoch 86/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.2821 - val_accuracy: 0.7857 - val_loss: 0.5322\n",
      "Epoch 87/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9173 - loss: 0.3097 - val_accuracy: 0.7857 - val_loss: 0.5271\n",
      "Epoch 88/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9199 - loss: 0.2650 - val_accuracy: 0.7857 - val_loss: 0.5191\n",
      "Epoch 89/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8854 - loss: 0.3316 - val_accuracy: 0.7857 - val_loss: 0.5167\n",
      "Epoch 90/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9463 - loss: 0.2245 - val_accuracy: 0.7857 - val_loss: 0.5103\n",
      "Epoch 91/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.2343 - val_accuracy: 0.7857 - val_loss: 0.5021\n",
      "Epoch 92/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8940 - loss: 0.2844 - val_accuracy: 0.7857 - val_loss: 0.4987\n",
      "Epoch 93/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.2450 - val_accuracy: 0.7857 - val_loss: 0.4867\n",
      "Epoch 94/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9116 - loss: 0.2644 - val_accuracy: 0.7857 - val_loss: 0.4861\n",
      "Epoch 95/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8993 - loss: 0.2755 - val_accuracy: 0.7857 - val_loss: 0.4736\n",
      "Epoch 96/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8970 - loss: 0.2583 - val_accuracy: 0.7857 - val_loss: 0.4663\n",
      "Epoch 97/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.2205 - val_accuracy: 0.7857 - val_loss: 0.4579\n",
      "Epoch 98/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8742 - loss: 0.2814 - val_accuracy: 0.7857 - val_loss: 0.4607\n",
      "Epoch 99/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9117 - loss: 0.2320 - val_accuracy: 0.7857 - val_loss: 0.4591\n",
      "Epoch 100/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.2262 - val_accuracy: 0.8571 - val_loss: 0.4535\n",
      "Epoch 101/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9182 - loss: 0.2286 - val_accuracy: 0.8571 - val_loss: 0.4544\n",
      "Epoch 102/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8949 - loss: 0.2388 - val_accuracy: 0.8571 - val_loss: 0.4400\n",
      "Epoch 103/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8998 - loss: 0.2285 - val_accuracy: 0.8571 - val_loss: 0.4391\n",
      "Epoch 104/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.2141 - val_accuracy: 0.8571 - val_loss: 0.4386\n",
      "Epoch 105/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8958 - loss: 0.2513 - val_accuracy: 0.8571 - val_loss: 0.4360\n",
      "Epoch 106/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.1989 - val_accuracy: 0.8571 - val_loss: 0.4323\n",
      "Epoch 107/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9058 - loss: 0.2132 - val_accuracy: 0.8571 - val_loss: 0.4245\n",
      "Epoch 108/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9016 - loss: 0.2284 - val_accuracy: 0.8571 - val_loss: 0.4199\n",
      "Epoch 109/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.1867 - val_accuracy: 0.8571 - val_loss: 0.4135\n",
      "Epoch 110/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9201 - loss: 0.2058 - val_accuracy: 0.8571 - val_loss: 0.4149\n",
      "Epoch 111/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.2053 - val_accuracy: 0.8571 - val_loss: 0.4091\n",
      "Epoch 112/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2164 - val_accuracy: 0.8571 - val_loss: 0.4077\n",
      "Epoch 113/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.1462 - val_accuracy: 0.8571 - val_loss: 0.4060\n",
      "Epoch 114/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9283 - loss: 0.1878 - val_accuracy: 0.8571 - val_loss: 0.3999\n",
      "Epoch 115/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9318 - loss: 0.1819 - val_accuracy: 0.8571 - val_loss: 0.3970\n",
      "Epoch 116/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2082 - val_accuracy: 0.8571 - val_loss: 0.3933\n",
      "Epoch 117/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9428 - loss: 0.1720 - val_accuracy: 0.8571 - val_loss: 0.3928\n",
      "Epoch 118/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8983 - loss: 0.2183 - val_accuracy: 0.8571 - val_loss: 0.3917\n",
      "Epoch 119/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.1491 - val_accuracy: 0.8571 - val_loss: 0.3822\n",
      "Epoch 120/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9610 - loss: 0.1587 - val_accuracy: 0.8571 - val_loss: 0.3768\n",
      "Epoch 121/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9459 - loss: 0.1607 - val_accuracy: 0.8571 - val_loss: 0.3745\n",
      "Epoch 122/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1816 - val_accuracy: 0.8571 - val_loss: 0.3790\n",
      "Epoch 123/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.2055 - val_accuracy: 0.8571 - val_loss: 0.3683\n",
      "Epoch 124/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9668 - loss: 0.1522 - val_accuracy: 0.8571 - val_loss: 0.3638\n",
      "Epoch 125/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9599 - loss: 0.1701 - val_accuracy: 0.8571 - val_loss: 0.3622\n",
      "Epoch 126/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.1376 - val_accuracy: 0.8571 - val_loss: 0.3548\n",
      "Epoch 127/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9628 - loss: 0.1608 - val_accuracy: 0.8571 - val_loss: 0.3554\n",
      "Epoch 128/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9495 - loss: 0.1784 - val_accuracy: 0.8571 - val_loss: 0.3536\n",
      "Epoch 129/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.1452 - val_accuracy: 0.8571 - val_loss: 0.3455\n",
      "Epoch 130/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.1434 - val_accuracy: 0.8571 - val_loss: 0.3383\n",
      "Epoch 131/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9629 - loss: 0.1509 - val_accuracy: 0.8571 - val_loss: 0.3438\n",
      "Epoch 132/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9731 - loss: 0.1555 - val_accuracy: 0.8571 - val_loss: 0.3448\n",
      "Epoch 133/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.1434 - val_accuracy: 0.8571 - val_loss: 0.3392\n",
      "Epoch 134/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.1356 - val_accuracy: 0.8571 - val_loss: 0.3368\n",
      "Epoch 135/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.1419 - val_accuracy: 0.8571 - val_loss: 0.3292\n",
      "Epoch 136/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.1837 - val_accuracy: 0.8571 - val_loss: 0.3285\n",
      "Epoch 137/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.1099 - val_accuracy: 0.8571 - val_loss: 0.3284\n",
      "Epoch 138/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.1218 - val_accuracy: 0.8571 - val_loss: 0.3262\n",
      "Epoch 139/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.1141 - val_accuracy: 0.8571 - val_loss: 0.3204\n",
      "Epoch 140/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.1401 - val_accuracy: 0.8571 - val_loss: 0.3149\n",
      "Epoch 141/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.1728 - val_accuracy: 0.8571 - val_loss: 0.3156\n",
      "Epoch 142/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.1357 - val_accuracy: 0.8571 - val_loss: 0.3081\n",
      "Epoch 143/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.1426 - val_accuracy: 0.8571 - val_loss: 0.3127\n",
      "Epoch 144/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.1207 - val_accuracy: 0.8571 - val_loss: 0.3075\n",
      "Epoch 145/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 0.1400 - val_accuracy: 0.8571 - val_loss: 0.3024\n",
      "Epoch 146/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.1494 - val_accuracy: 0.8571 - val_loss: 0.3008\n",
      "Epoch 147/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.1363 - val_accuracy: 0.8571 - val_loss: 0.2929\n",
      "Epoch 148/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9621 - loss: 0.1439 - val_accuracy: 0.8571 - val_loss: 0.2978\n",
      "Epoch 149/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9587 - loss: 0.1548 - val_accuracy: 0.8571 - val_loss: 0.2970\n",
      "Epoch 150/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1344 - val_accuracy: 0.8571 - val_loss: 0.2896\n",
      "Epoch 151/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.1251 - val_accuracy: 0.8571 - val_loss: 0.2891\n",
      "Epoch 152/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.1205 - val_accuracy: 0.8571 - val_loss: 0.2847\n",
      "Epoch 153/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.1103 - val_accuracy: 0.8571 - val_loss: 0.2850\n",
      "Epoch 154/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.1351 - val_accuracy: 0.8571 - val_loss: 0.2814\n",
      "Epoch 155/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9587 - loss: 0.1475 - val_accuracy: 0.8571 - val_loss: 0.2755\n",
      "Epoch 156/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.1063 - val_accuracy: 0.8571 - val_loss: 0.2752\n",
      "Epoch 157/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9646 - loss: 0.1415 - val_accuracy: 0.8571 - val_loss: 0.2734\n",
      "Epoch 158/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0953 - val_accuracy: 0.8571 - val_loss: 0.2681\n",
      "Epoch 159/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.1297 - val_accuracy: 0.8571 - val_loss: 0.2710\n",
      "Epoch 160/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.1216 - val_accuracy: 0.8571 - val_loss: 0.2709\n",
      "Epoch 161/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1230 - val_accuracy: 0.8571 - val_loss: 0.2650\n",
      "Epoch 162/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0966 - val_accuracy: 0.8571 - val_loss: 0.2626\n",
      "Epoch 163/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.1038 - val_accuracy: 0.8571 - val_loss: 0.2616\n",
      "Epoch 164/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9805 - loss: 0.1068 - val_accuracy: 0.8571 - val_loss: 0.2559\n",
      "Epoch 165/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.1052 - val_accuracy: 0.8571 - val_loss: 0.2603\n",
      "Epoch 166/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9693 - loss: 0.1102 - val_accuracy: 0.8571 - val_loss: 0.2583\n",
      "Epoch 167/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0956 - val_accuracy: 0.8571 - val_loss: 0.2551\n",
      "Epoch 168/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.1100 - val_accuracy: 0.8571 - val_loss: 0.2520\n",
      "Epoch 169/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.1086 - val_accuracy: 0.8571 - val_loss: 0.2515\n",
      "Epoch 170/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0925 - val_accuracy: 0.8571 - val_loss: 0.2472\n",
      "Epoch 171/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0866 - val_accuracy: 0.8571 - val_loss: 0.2498\n",
      "Epoch 172/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.1005 - val_accuracy: 0.8571 - val_loss: 0.2493\n",
      "Epoch 173/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.1015 - val_accuracy: 0.8571 - val_loss: 0.2456\n",
      "Epoch 174/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.1100 - val_accuracy: 0.8571 - val_loss: 0.2451\n",
      "Epoch 175/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0849 - val_accuracy: 0.8571 - val_loss: 0.2397\n",
      "Epoch 176/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0750 - val_accuracy: 0.8571 - val_loss: 0.2353\n",
      "Epoch 177/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.0970 - val_accuracy: 0.8571 - val_loss: 0.2382\n",
      "Epoch 178/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.0945 - val_accuracy: 0.8571 - val_loss: 0.2382\n",
      "Epoch 179/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0847 - val_accuracy: 0.8571 - val_loss: 0.2330\n",
      "Epoch 180/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0712 - val_accuracy: 0.8571 - val_loss: 0.2319\n",
      "Epoch 181/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0850 - val_accuracy: 0.8571 - val_loss: 0.2277\n",
      "Epoch 182/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0785 - val_accuracy: 0.8571 - val_loss: 0.2252\n",
      "Epoch 183/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0879 - val_accuracy: 0.8571 - val_loss: 0.2267\n",
      "Epoch 184/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0807 - val_accuracy: 0.8571 - val_loss: 0.2244\n",
      "Epoch 185/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0781 - val_accuracy: 0.8571 - val_loss: 0.2222\n",
      "Epoch 186/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0915 - val_accuracy: 0.8571 - val_loss: 0.2234\n",
      "Epoch 187/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9813 - loss: 0.0777 - val_accuracy: 0.8571 - val_loss: 0.2218\n",
      "Epoch 188/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0689 - val_accuracy: 0.8571 - val_loss: 0.2179\n",
      "Epoch 189/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0925 - val_accuracy: 0.8571 - val_loss: 0.2205\n",
      "Epoch 190/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0698 - val_accuracy: 0.8571 - val_loss: 0.2150\n",
      "Epoch 191/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0869 - val_accuracy: 0.8571 - val_loss: 0.2113\n",
      "Epoch 192/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0840 - val_accuracy: 0.8571 - val_loss: 0.2120\n",
      "Epoch 193/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0661 - val_accuracy: 0.8571 - val_loss: 0.2096\n",
      "Epoch 194/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.0860 - val_accuracy: 0.8571 - val_loss: 0.2106\n",
      "Epoch 195/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0830 - val_accuracy: 0.8571 - val_loss: 0.2085\n",
      "Epoch 196/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0831 - val_accuracy: 0.9286 - val_loss: 0.2097\n",
      "Epoch 197/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0735 - val_accuracy: 0.9286 - val_loss: 0.2073\n",
      "Epoch 198/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0736 - val_accuracy: 0.9286 - val_loss: 0.2011\n",
      "Epoch 199/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.0806 - val_accuracy: 0.9286 - val_loss: 0.2041\n",
      "Epoch 200/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0641 - val_accuracy: 0.9286 - val_loss: 0.2010\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training TensorFlow model...\")\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=200, \n",
    "    batch_size=16, \n",
    "    validation_split=0.1 # Use 10% of training data for validation during training\n",
    ")\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Optionally plot training history\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TFLite Conversion\n",
    "\n",
    "Convert the trained Keras model to a quantized TensorFlow Lite model using a representative dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Keras model to TFLite...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdgi6ni8e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdgi6ni8e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpdgi6ni8e'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 5), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140301682214336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301682219264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301682223664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301682228240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301682228592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301682347520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "TFLite conversion complete.\n",
      "TFLite model size: 3872 bytes\n",
      "TFLite model saved to Model/drug_model_quant.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/.local/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1745347320.488301   34627 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1745347320.488358   34627 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-23 00:12:00.489046: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdgi6ni8e\n",
      "2025-04-23 00:12:00.489400: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-23 00:12:00.489407: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpdgi6ni8e\n",
      "I0000 00:00:1745347320.492081   34627 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-04-23 00:12:00.492575: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-23 00:12:00.511905: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpdgi6ni8e\n",
      "2025-04-23 00:12:00.517142: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 28100 microseconds.\n",
      "2025-04-23 00:12:00.526982: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    }
   ],
   "source": [
    "# Set up a representative dataset generator for TFLite quantization\n",
    "def representative_data_gen():\n",
    "    # Use a subset of training data. TFLite recommends ~100-500 samples.\n",
    "    # Ensure the data is in the expected float32 format and correct shape (batch_size, num_features)\n",
    "    for i in range(min(100, len(X_train))):\n",
    "        # pick a sample\n",
    "        sample = X_train[i]\n",
    "        # Yield the sample formatted as a list containing a batch tensor\n",
    "        yield [sample.astype(np.float32).reshape(1, -1)] # Reshape sample to (1, num_features)\n",
    "\n",
    "# Convert Keras model to TFLite\n",
    "print(\"Converting Keras model to TFLite...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT] # Apply default optimizations (quantization)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Specify target operations and desired input/output types for full integer quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type  = tf.uint8 # Force input to be uint8\n",
    "converter.inference_output_type = tf.uint8 # Force output to be uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "print(\"TFLite conversion complete.\")\n",
    "\n",
    "# Save TFLite model to disk\n",
    "tflite_model_path = \"Model/drug_model_quant.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TFLite model size:\", len(tflite_model), \"bytes\")\n",
    "print(f\"TFLite model saved to {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Reporting\n",
    "\n",
    "Evaluate the trained Keras model on the test set and generate artifacts for reporting (metrics file and confusion matrix plot). Note that the evaluation here is of the Keras model, not the quantized TFLite model, for simplicity in matching the original script's output structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (Keras) = 93.33%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Generating confusion matrix plot...\n",
      "Confusion matrix plot saved to Results/model_results.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the Keras model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy (Keras) = {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get predictions from the Keras model for plotting/matrix calculation\n",
    "keras_predictions_probs = model.predict(X_test)\n",
    "keras_predictions_indices = np.argmax(keras_predictions_probs, axis=1)\n",
    "\n",
    "# Decode predictions from indices back to original labels for confusion matrix\n",
    "reverse_label_mapping = {i: label for label, i in label_mapping.items()}\n",
    "keras_predicted_labels = np.vectorize(reverse_label_mapping.get)(keras_predictions_indices)\n",
    "test_true_labels = np.vectorize(reverse_label_mapping.get)(y_test)\n",
    "\n",
    "# For the confusion matrix plot, we need the unique classes in their original string format\n",
    "class_names = list(label_mapping.keys()) # Get class names from the mapping\n",
    "\n",
    "# Calculate confusion matrix using decoded labels\n",
    "cm = confusion_matrix(test_true_labels, keras_predicted_labels, labels=class_names)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "print(\"Generating confusion matrix plot...\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6)) # Adjust figure size if needed\n",
    "disp.plot(ax=ax)\n",
    "plt.title('Confusion Matrix (Keras Model)')\n",
    "plt.savefig(\"Results/model_results.png\", dpi=120)\n",
    "print(\"Confusion matrix plot saved to Results/model_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Accuracy to Results/metrics.txt: 0.9333\n",
      "Metrics saved to Results/metrics.txt\n"
     ]
    }
   ],
   "source": [
    "# Write metrics to file\n",
    "# Use the accuracy obtained directly from model.evaluate\n",
    "print(f\"Saving Accuracy to Results/metrics.txt: {accuracy:.4f}\")\n",
    "with open(\"Results/metrics.txt\", \"w\") as outfile:\n",
    "    # Note: F1 score for multi-class from quantized model is non-trivial to report here directly.\n",
    "    # Reporting Keras accuracy as the primary metric for this updated pipeline step.\n",
    "    outfile.write(f\"\\nTest Accuracy (Keras) = {accuracy:.4f}\")\n",
    "print(\"Metrics saved to Results/metrics.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
